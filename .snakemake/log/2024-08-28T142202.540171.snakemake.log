Building DAG of jobs...
shared_storage_local_copies: True
remote_exec: False
Using shell: /usr/bin/bash
Provided cores: 128
Rules claiming more threads will be scaled down.
Job stats:
job      count
-----  -------
all          1
total        1

Resources before job selection: {'_cores': 128, '_nodes': 9223372036854775807}
Ready jobs (1)
Select jobs to execute...
Using greedy selector because only single job has to be scheduled.
Selected jobs (1)
Resources after job selection: {'_cores': 127, '_nodes': 9223372036854775806}
Execute 1 jobs...

[Wed Aug 28 14:22:02 2024]
localrule all:
    input: /n/zanderson/SNP-plot-snake/SNP-Plots/SNP-plot-20240827.svg
    jobid: 0
    reason: Forced execution
    resources: tmpdir=/tmp

Completion of job ['all'] reported to scheduler.
jobs registered as running before removal {all}
[Wed Aug 28 14:22:02 2024]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2024-08-28T142202.540171.snakemake.log
unlocking
removing lock
removing lock
removed all locks
